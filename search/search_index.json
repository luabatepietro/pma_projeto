{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#template-de-entrega","title":"Template de Entrega","text":"Edi\u00e7\u00e3o <p>2025.2</p>"},{"location":"#grupokit-x","title":"Grupo/Kit X","text":"<ol> <li>Lucas Abatepietro</li> <li>Marcelo Alonso</li> <li>Henrique Bucci</li> </ol> <p>Instru\u00e7\u00f5es</p> <p>Voc\u00eas devem utilizar este template como um bloco de notas para registrar o que foi feito e o que falta fazer. Voc\u00eas devem adicionar as informa\u00e7\u00f5es necess\u00e1rias. O template deve ser editado e atualizado a cada entrega, registrando assim a data de entrega e o que foi feito at\u00e9 o momento via Git.</p>"},{"location":"#entregas","title":"Entregas","text":"<ul> <li> Product API - Data 24/10/2025</li> <li> Order API - Data 24/10/2025</li> <li> Exchange API - Data 24/10/2025</li> <li> Jenkins -  24/10/2025</li> <li> K8s - 24/10/2025</li> </ul>"},{"location":"#diagramas","title":"Diagramas","text":"<p>Use o Mermaid para criar os diagramas de documenta\u00e7\u00e3o.</p> <p>Mermaid Live Editor</p> <pre><code>flowchart TD\n    Deployment:::orange --&gt;|defines| ReplicaSet\n    ReplicaSet --&gt;|manages| pod((Pod))\n    pod:::red --&gt;|runs| Container\n    Deployment --&gt;|scales| pod\n    Deployment --&gt;|updates| pod\n\n    Service:::orange --&gt;|exposes| pod\n\n    subgraph\n        ConfigMap:::orange\n        Secret:::orange\n    end\n\n    ConfigMap --&gt; Deployment\n    Secret --&gt; Deployment\n    classDef red fill:#f55\n    classDef orange fill:#ffa500</code></pre>"},{"location":"#codigos","title":"C\u00f3digos","text":"De um arquivo remotoAnota\u00e7\u00f5es no c\u00f3digo main.yaml<pre><code>name: ci\non:\n  - push\n  - pull_request\n\n# Environment\nenv:\n  CI: true\n  PYTHON_VERSION: 3.12\n\n# Jobs to run\njobs:\n\n  # Build and deploy documentation site\n  deploy:\n    if: github.event_name != 'pull_request' &amp;&amp; github.ref == 'refs/heads/main'\n    runs-on: ubuntu-latest\n    steps:\n\n      # Checkout source form GitHub\n      - uses: actions/checkout@v4\n\n      # Install Python runtime and dependencies\n      - uses: actions/setup-python@v4\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      # pip\n      - run: |\n          pip install -r requirements.txt\n\n      # deploy\n      - run: |\n          mkdocs gh-deploy --force\n</code></pre> compose.yaml<pre><code>name: app\n\n    db:\n        image: postgres:17\n        environment:\n            POSTGRES_DB: ${POSTGRES_DB:-projeto} # (1)!\n            POSTGRES_USER: ${POSTGRES_USER:-projeto}\n            POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-projeto}\n        ports:\n            - 5432:5432 #(2)!\n</code></pre> <ol> <li> <p>Caso a vari\u00e1vel de ambiente <code>POSTGRES_DB</code> n\u00e3o exista ou seja nula - n\u00e3o seja definida no arquivo <code>.env</code> - o valor padr\u00e3o ser\u00e1 <code>projeto</code>. Vide documenta\u00e7\u00e3o.</p> </li> <li> <p>Aqui \u00e9 feito um t\u00fanel da porta 5432 do container do banco de dados para a porta 5432 do host (no caso localhost). Em um ambiente de produ\u00e7\u00e3o, essa porta n\u00e3o deve ser exposta, pois ningu\u00e9m de fora do compose deveria acessar o banco de dados diretamente.</p> </li> </ol>"},{"location":"#exemplo-de-video","title":"Exemplo de v\u00eddeo","text":"<p>Lorem ipsum dolor sit amet</p>"},{"location":"#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"},{"location":"notebook1/ex1_data/","title":"Ex1 data","text":"In\u00a0[14]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\nclass0 = {\n    \"x\": np.random.normal(2, 0.8, size=100),\n    \"y\": np.random.normal(3, 2.5, size=100)\n}\n\nclass1 = {\n    \"x\": np.random.normal(5, 1.2, size=100),\n    \"y\": np.random.normal(6, 1.9, size=100)\n}\n\nclass2 = {\n    \"x\": np.random.normal(8, 0.9, size=100),\n    \"y\": np.random.normal(1, 0.9, size=100)\n}\n\nclass3 = {\n    \"x\": np.random.normal(15, 0.5, size=100),\n    \"y\": np.random.normal(4, 2.0, size=100)\n}\n\n\nplt.figure(figsize=(8,6))\nplt.scatter(class0[\"x\"], class0[\"y\"], label=\"Class 0\", alpha=0.6)\nplt.scatter(class1[\"x\"], class1[\"y\"], label=\"Class 1\", alpha=0.6)\nplt.scatter(class2[\"x\"], class2[\"y\"], label=\"Class 2\", alpha=0.6)\nplt.scatter(class3[\"x\"], class3[\"y\"], label=\"Class 3\", alpha=0.6)\nplt.legend()\nplt.xlabel(\"X1\")\nplt.ylabel(\"X2\")\nplt.title(\"Dados Sinteticos Aleat\u00f3rios\")\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  np.random.seed(42)  class0 = {     \"x\": np.random.normal(2, 0.8, size=100),     \"y\": np.random.normal(3, 2.5, size=100) }  class1 = {     \"x\": np.random.normal(5, 1.2, size=100),     \"y\": np.random.normal(6, 1.9, size=100) }  class2 = {     \"x\": np.random.normal(8, 0.9, size=100),     \"y\": np.random.normal(1, 0.9, size=100) }  class3 = {     \"x\": np.random.normal(15, 0.5, size=100),     \"y\": np.random.normal(4, 2.0, size=100) }   plt.figure(figsize=(8,6)) plt.scatter(class0[\"x\"], class0[\"y\"], label=\"Class 0\", alpha=0.6) plt.scatter(class1[\"x\"], class1[\"y\"], label=\"Class 1\", alpha=0.6) plt.scatter(class2[\"x\"], class2[\"y\"], label=\"Class 2\", alpha=0.6) plt.scatter(class3[\"x\"], class3[\"y\"], label=\"Class 3\", alpha=0.6) plt.legend() plt.xlabel(\"X1\") plt.ylabel(\"X2\") plt.title(\"Dados Sinteticos Aleat\u00f3rios\") plt.show()  <ol> <li><p>Plot the Data: Create a 2D scatter plot showing all the data points. Use a different color for each class to make them distinguishable.</p> </li> <li><p>Analyze and Draw Boundaries:</p> <ol> <li>Examine the scatter plot carefully. Describe the distribution and overlap of the four classes.<ul> <li>Class 0 and 1 have the most overlap, being pretty ditinguishable from the other two classes (numbers 2 and 3). The most segregated one is class 3, being at the far end of the X1 axis of the plot.</li> </ul> </li> <li>Based on your visual inspection, could a simple, linear boundary separate all classes?<ul> <li>I would argue that a line can be made to separate classes from each other, but the line would also put different classes on the same side. This would mean we would need at minimum a second line to properly separate all classes.</li> </ul> </li> <li>On your plot, sketch the decision boundaries that you think a trained neural network might learn to separate these classes.</li> </ol> <p> </p> </li> </ol> In\u00a0[15]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\nnp.random.seed(42)\n\nmu_A = [0, 0, 0, 0, 0]\nSigma_A = np.array([\n    [1.0, 0.8, 0.1, 0.0, 0.0],\n    [0.8, 1.0, 0.3, 0.0, 0.0],\n    [0.1, 0.3, 1.0, 0.5, 0.0],\n    [0.0, 0.0, 0.5, 1.0, 0.2],\n    [0.0, 0.0, 0.0, 0.2, 1.0]\n])\n\nmu_B = [1.5, 1.5, 1.5, 1.5, 1.5]\nSigma_B = np.array([\n    [1.5, -0.7, 0.2, 0.0, 0.0],\n    [-0.7, 1.5, 0.4, 0.0, 0.0],\n    [0.2, 0.4, 1.5, 0.6, 0.0],\n    [0.0, 0.0, 0.6, 1.5, 0.3],\n    [0.0, 0.0, 0.0, 0.3, 1.5]\n])\n\nclass_A = np.random.multivariate_normal(mu_A, Sigma_A, size=500)\nclass_B = np.random.multivariate_normal(mu_B, Sigma_B, size=500)\n\nX = np.vstack((class_A, class_B))\ny = np.array([0]*500 + [1]*500)\n\nprint(\"Dataset shape:\", X.shape)\n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X)\n\nplt.figure(figsize=(8,6))\nplt.scatter(X_pca[y==0, 0], X_pca[y==0, 1], alpha=0.6, label=\"Class A\")\nplt.scatter(X_pca[y==1, 0], X_pca[y==1, 1], alpha=0.6, label=\"Class B\")\nplt.title(\"PCA de dados Sint\u00e9ticos 5D - Redu\u00e7\u00e3o para 2D\")\nplt.xlabel(\"PC1\")\nplt.ylabel(\"PC2\")\nplt.legend()\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from sklearn.decomposition import PCA  np.random.seed(42)  mu_A = [0, 0, 0, 0, 0] Sigma_A = np.array([     [1.0, 0.8, 0.1, 0.0, 0.0],     [0.8, 1.0, 0.3, 0.0, 0.0],     [0.1, 0.3, 1.0, 0.5, 0.0],     [0.0, 0.0, 0.5, 1.0, 0.2],     [0.0, 0.0, 0.0, 0.2, 1.0] ])  mu_B = [1.5, 1.5, 1.5, 1.5, 1.5] Sigma_B = np.array([     [1.5, -0.7, 0.2, 0.0, 0.0],     [-0.7, 1.5, 0.4, 0.0, 0.0],     [0.2, 0.4, 1.5, 0.6, 0.0],     [0.0, 0.0, 0.6, 1.5, 0.3],     [0.0, 0.0, 0.0, 0.3, 1.5] ])  class_A = np.random.multivariate_normal(mu_A, Sigma_A, size=500) class_B = np.random.multivariate_normal(mu_B, Sigma_B, size=500)  X = np.vstack((class_A, class_B)) y = np.array([0]*500 + [1]*500)  print(\"Dataset shape:\", X.shape)  pca = PCA(n_components=2) X_pca = pca.fit_transform(X)  plt.figure(figsize=(8,6)) plt.scatter(X_pca[y==0, 0], X_pca[y==0, 1], alpha=0.6, label=\"Class A\") plt.scatter(X_pca[y==1, 0], X_pca[y==1, 1], alpha=0.6, label=\"Class B\") plt.title(\"PCA de dados Sint\u00e9ticos 5D - Redu\u00e7\u00e3o para 2D\") plt.xlabel(\"PC1\") plt.ylabel(\"PC2\") plt.legend() plt.show()  <pre>Dataset shape: (1000, 5)\n</pre> <ol> <li>Visualize the Data: Since you cannot directly plot a 5D graph, you must reduce its dimensionality.<ul> <li>Use a technique like Principal Component Analysis (PCA) to project the 5D data down to 2 dimensions.</li> <li>Create a scatter plot of this 2D representation, coloring the points by their class (A or B).</li> </ul> </li> <li>Analyze the Plots:<ol> <li><p>Based on your 2D projection, describe the relationship between the two classes.</p> <ul> <li>Very intertwined, making it extremely difficult to separate them clearly. They do tend to different sides of the plot (in the x-axis), but they do have noticeable overlap.</li> </ul> </li> <li><p>Discuss the linear separability of the data. Explain why this type of data structure poses a challenge for simple linear models and would likely require a multi-layer neural network with non-linear activation functions to be classified accurately.</p> <ul> <li>Creating a single line that segregates these two classes is not possible, given that they do have overlap. If you were to trace a line between them, it would end up inevitably classifying class A as class B and vice-versa.</li> </ul> </li> </ol> </li> </ol> <p> </p> In\u00a0[16]: Copied! <pre>import pandas as pd\n\ndf = pd.read_csv(\"../../../data/SpaceshipTitanic/train.csv\")\n\ndf.head()\n</pre> import pandas as pd  df = pd.read_csv(\"../../../data/SpaceshipTitanic/train.csv\")  df.head() Out[16]: PassengerId HomePlanet CryoSleep Cabin Destination Age VIP RoomService FoodCourt ShoppingMall Spa VRDeck Name Transported 0 0001_01 Europa False B/0/P TRAPPIST-1e 39.0 False 0.0 0.0 0.0 0.0 0.0 Maham Ofracculy False 1 0002_01 Earth False F/0/S TRAPPIST-1e 24.0 False 109.0 9.0 25.0 549.0 44.0 Juanna Vines True 2 0003_01 Europa False A/0/S TRAPPIST-1e 58.0 True 43.0 3576.0 0.0 6715.0 49.0 Altark Susent False 3 0003_02 Europa False A/0/S TRAPPIST-1e 33.0 False 0.0 1283.0 371.0 3329.0 193.0 Solam Susent False 4 0004_01 Earth False F/1/S TRAPPIST-1e 16.0 False 303.0 70.0 151.0 565.0 2.0 Willy Santantines True In\u00a0[17]: Copied! <pre>null_counts = df.isnull().sum()\n\nprint(\"Null values per column:\")\nprint(null_counts) \n</pre> null_counts = df.isnull().sum()  print(\"Null values per column:\") print(null_counts)  <pre>Null values per column:\nPassengerId       0\nHomePlanet      201\nCryoSleep       217\nCabin           199\nDestination     182\nAge             179\nVIP             203\nRoomService     181\nFoodCourt       183\nShoppingMall    208\nSpa             183\nVRDeck          188\nName            200\nTransported       0\ndtype: int64\n</pre> <p>For these missing values, we must treat numerical and categorical features separately.</p> <p>For numerical features, we use a Simple Imputer to fill null values. In this instance, I chose the Median value to be used as filler. After that, we use a Standard Scaler to put all values centered at 0.</p> <p>For categorical features, we use the most frequent class as a fill-in for missing values, and pass it to a OneHotEncoder afterwards so our categorical values become boolean features. In this case, this gave us 26 features compared to our initial 14</p> In\u00a0[34]: Copied! <pre>from sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nimport pandas as pd\n\n\nX = df.drop([\"PassengerId\", \"Name\"], axis=1)\n\nprint(\"Original Data Without PassengerId and Name\")\nprint(X.shape)\n\nX[[\"Deck\", \"Num\", \"Side\"]] = X[\"Cabin\"].str.split(\"/\", expand=True)\nX.drop(\"Cabin\", axis=1, inplace=True)\n\nprint(\"\\nAfter splitting Cabin into Deck, Number and Side of ship (3 new columns)\")\nprint(X.shape)\n\nnum_features = [\"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]\ncat_features = [\"HomePlanet\", \"CryoSleep\", \"Destination\", \"VIP\", \"Deck\", \"Side\"]\n\nnum_pipeline = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"median\")),\n    (\"scaler\", StandardScaler())\n])\n\ncat_pipeline = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n])\n\npreprocessor = ColumnTransformer([\n    (\"num\", num_pipeline, num_features),\n    (\"cat\", cat_pipeline, cat_features)\n])\n\nX_processed = preprocessor.fit_transform(X)\n\nprint(\"\\nAfter Pipelines\")\nprint(X_processed.shape)\n</pre> from sklearn.preprocessing import StandardScaler, OneHotEncoder from sklearn.impute import SimpleImputer from sklearn.compose import ColumnTransformer from sklearn.pipeline import Pipeline import pandas as pd   X = df.drop([\"PassengerId\", \"Name\"], axis=1)  print(\"Original Data Without PassengerId and Name\") print(X.shape)  X[[\"Deck\", \"Num\", \"Side\"]] = X[\"Cabin\"].str.split(\"/\", expand=True) X.drop(\"Cabin\", axis=1, inplace=True)  print(\"\\nAfter splitting Cabin into Deck, Number and Side of ship (3 new columns)\") print(X.shape)  num_features = [\"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"] cat_features = [\"HomePlanet\", \"CryoSleep\", \"Destination\", \"VIP\", \"Deck\", \"Side\"]  num_pipeline = Pipeline([     (\"imputer\", SimpleImputer(strategy=\"median\")),     (\"scaler\", StandardScaler()) ])  cat_pipeline = Pipeline([     (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),     (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")) ])  preprocessor = ColumnTransformer([     (\"num\", num_pipeline, num_features),     (\"cat\", cat_pipeline, cat_features) ])  X_processed = preprocessor.fit_transform(X)  print(\"\\nAfter Pipelines\") print(X_processed.shape) <pre>Original Data Without PassengerId and Name\n(8693, 12)\n\nAfter splitting Cabin into Deck, Number and Side of ship (3 new columns)\n(8693, 14)\n\nAfter Pipelines\n(8693, 26)\n</pre> <ol> <li>Preprocess the Data: Your goal is to clean and transform the data so it can be fed into a neural network. The <code>tanh</code> activation function produces outputs in the range <code>[-1, 1]</code>, so your input data should be scaled appropriately for stable training.<ul> <li>Handle Missing Data: Devise and implement a strategy to handle the missing values in all the affected columns. Justify your choices.</li> <li>Encode Categorical Features: Convert categorical columns like <code>HomePlanet</code>, <code>CryoSleep</code>, and <code>Destination</code> into a numerical format. One-hot encoding is a good choice.</li> <li>Normalize/Standardize Numerical Features: Scale the numerical columns (e.g., <code>Age</code>, <code>RoomService</code>, etc.). Since the <code>tanh</code> activation function is centered at zero and outputs values in <code>[-1, 1]</code>, Standardization (to mean 0, std 1) or Normalization to a <code>[-1, 1]</code> range are excellent choices. Implement one and explain why it is a good practice for training neural networks with this activation function.</li> </ul> </li> <li>Visualize the Results:<ul> <li>Create histograms for one or two numerical features (like <code>FoodCourt</code> or <code>Age</code>) before and after scaling to show the effect of your transformation.</li> </ul> </li> </ol> In\u00a0[35]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\nfig, axes = plt.subplots(len(num_features), 2, figsize=(25, 4*len(num_features)))\n\nfor i in range(len(num_features)):\n    \n    feature = num_features[i]\n    \n    df[feature].hist(ax=axes[i, 0], bins=30, color=\"skyblue\")\n    axes[i, 0].set_title(f\"{feature} before scaling\")\n\n    scaled = StandardScaler().fit_transform(df[[feature]].fillna(df[feature].median()))\n    pd.Series(scaled.ravel()).hist(ax=axes[i, 1], bins=30, color=\"salmon\")\n    axes[i, 1].set_title(f\"{feature} after standardization\")\n\nplt.tight_layout()\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt import pandas as pd from sklearn.preprocessing import StandardScaler  fig, axes = plt.subplots(len(num_features), 2, figsize=(25, 4*len(num_features)))  for i in range(len(num_features)):          feature = num_features[i]          df[feature].hist(ax=axes[i, 0], bins=30, color=\"skyblue\")     axes[i, 0].set_title(f\"{feature} before scaling\")      scaled = StandardScaler().fit_transform(df[[feature]].fillna(df[feature].median()))     pd.Series(scaled.ravel()).hist(ax=axes[i, 1], bins=30, color=\"salmon\")     axes[i, 1].set_title(f\"{feature} after standardization\")  plt.tight_layout() plt.show()  <p>Notice that the shape of the graphs is maintained, but the values in the x-axis are centered to 0.</p>"},{"location":"notebook1/ex1_data/#exercise-1","title":"Exercise 1\u00b6","text":""},{"location":"notebook1/ex1_data/#exploring-class-separability-in-2d","title":"Exploring Class Separability in 2D\u00b6","text":"<p>Understanding how data is distributed is the first step before designing a network architecture. In this exercise, you will generate and visualize a two-dimensional dataset to explore how data distribution affects the complexity of the decision boundaries a neural network would need to learn.</p>"},{"location":"notebook1/ex1_data/#instructions","title":"Instructions\u00b6","text":"<ol> <li>Generate the Data: Create a synthetic dataset with a total of 400 samples, divided equally among 4 classes (100 samples each). Use a Gaussian distribution to generate the points for each class based on the following parameters:<ul> <li>Class 0: Mean = [2, 3], Standard Deviation = [0.8, 2.5]</li> <li>Class 1: Mean = [5, 6], Standard Deviation = [1.2, 1.9]</li> <li>Class 2: Mean = [8, 1], Standard Deviation = [0.9, 0.9]</li> <li>Class 3: Mean = [15, 4], Standard Deviation = [0.5, 2.0]</li> </ul> </li> </ol>"},{"location":"notebook1/ex1_data/#exercise-2","title":"Exercise 2\u00b6","text":""},{"location":"notebook1/ex1_data/#non-linearity-in-higher-dimensions","title":"Non-Linearity in Higher Dimensions\u00b6","text":"<p>Simple neural networks (like a Perceptron) can only learn linear boundaries. Deep networks excel when data is not linearly separable. This exercise challenges you to create and visualize such a dataset.</p>"},{"location":"notebook1/ex1_data/#instructions","title":"Instructions\u00b6","text":"<ol> <li><p>Generate the Data: Create a dataset with 500 samples for Class A and 500 samples for Class B. Use a multivariate normal distribution with the following parameters:</p> <ul> <li><p>Class A:</p> <p>Mean vector:</p> <p>$$\\mu_A = [0, 0, 0, 0, 0]$$</p> <p>Covariance matrix:</p> <p>$$   \\Sigma_A = \\begin{pmatrix}   1.0 &amp; 0.8 &amp; 0.1 &amp; 0.0 &amp; 0.0 \\\\   0.8 &amp; 1.0 &amp; 0.3 &amp; 0.0 &amp; 0.0 \\\\   0.1 &amp; 0.3 &amp; 1.0 &amp; 0.5 &amp; 0.0 \\\\   0.0 &amp; 0.0 &amp; 0.5 &amp; 1.0 &amp; 0.2 \\\\   0.0 &amp; 0.0 &amp; 0.0 &amp; 0.2 &amp; 1.0   \\end{pmatrix}   $$</p> </li> <li><p>Class B:</p> <p>Mean vector:</p> <p>$$\\mu_B = [1.5, 1.5, 1.5, 1.5, 1.5]$$</p> <p>Covariance matrix:</p> <p>$$   \\Sigma_B = \\begin{pmatrix}   1.5 &amp; -0.7 &amp; 0.2 &amp; 0.0 &amp; 0.0 \\\\   -0.7 &amp; 1.5 &amp; 0.4 &amp; 0.0 &amp; 0.0 \\\\   0.2 &amp; 0.4 &amp; 1.5 &amp; 0.6 &amp; 0.0 \\\\   0.0 &amp; 0.0 &amp; 0.6 &amp; 1.5 &amp; 0.3 \\\\   0.0 &amp; 0.0 &amp; 0.0 &amp; 0.3 &amp; 1.5   \\end{pmatrix}   $$</p> </li> </ul> </li> </ol>"},{"location":"notebook1/ex1_data/#exercise-3","title":"Exercise 3\u00b6","text":""},{"location":"notebook1/ex1_data/#preparing-real-world-data-for-a-neural-network","title":"Preparing Real-World Data for a Neural Network\u00b6","text":"<p>This exercise uses a real dataset from Kaggle. Your task is to perform the necessary preprocessing to make it suitable for a neural network that uses the hyperbolic tangent (<code>tanh</code>) activation function in its hidden layers.</p>"},{"location":"notebook1/ex1_data/#instructions","title":"Instructions\u00b6","text":"<ol> <li><p>Get the Data: Download the Spaceship Titanic dataset from Kaggle.</p> </li> <li><p>Describe the Data:</p> <ul> <li><p>Briefly describe the dataset's objective (i.e., what does the <code>Transported</code> column represent?).</p> <ul> <li>We're trying to predict if a passenger was transported to another dimension during the crash of the Spaceship Titanic, the value that represents whether or not the passenger was transported is in the <code>Transported column</code></li> </ul> </li> <li><p>List the features and identify which are numerical (e.g., <code>Age</code>, <code>RoomService</code>) and which are categorical (e.g., <code>HomePlanet</code>, <code>Destination</code>).</p> </li> <li><p>Investigate the dataset for missing values. Which columns have them, and how many?</p> </li> </ul> </li> </ol> <p>Categorical Columns -</p> <ul> <li>HomePlanet - The planet the passenger departed from, typically their planet of permanent residence.</li> <li>Cabin - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.</li> <li>Destination - The planet the passenger will be debarking to.</li> <li>Name - The first and last names of the passenger.</li> <li>PassengerId - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.</li> </ul> <p>Boolean Columns -</p> <ul> <li>Transported - Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict.</li> <li>VIP - Whether the passenger has paid for special VIP service during the voyage.</li> <li>CryoSleep - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.</li> </ul> <p>Numerical Columns -</p> <ul> <li>Age - The age of the passenger.</li> <li>RoomService, FoodCourt, ShoppingMall, Spa, VRDeck - Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities.</li> </ul>"},{"location":"projeto/","title":"Teste de carga","text":""},{"location":"projeto/#teste-de-carga-20","title":"Teste de carga - 20%","text":"<ul> <li>Desenvolvido por:<ul> <li>Lucas Abatepietro</li> <li>Marcelo Alonso</li> <li>Henrique Bucci</li> </ul> </li> </ul> <p>Vamos ver se nossa aplica\u00e7\u00e3o \u00e9 capaz de aguentar com um trafego que aumenta cada vez mais.</p> <p>Abaixo a um GIF mostrando como o nosso servi\u00e7o \u00e9 capaz de escalar conforme a demanda.</p> <p></p> <p>O que estamos fazendo nesse v\u00eddeo criamos tr\u00eas terminais: </p> <ol> <li>Cria o HPA (Horizontal Pod Autoscaler) para o <code>gateway</code>. Ele vai aumentar o num de pods baseado em quanto de CPU est\u00e1 sendo usado.</li> <li>Esse terminal serve para monitorar os pods (ou seja, para vermos se est\u00e1 sendo criado mais)</li> <li>Nesse que est\u00e1 sendo rodado o teste de carga, mandando bastante traf\u00e9go para nossa aplica\u00e7\u00e3o <code>gateway</code></li> </ol>"},{"location":"roteiro1/","title":"Product API","text":""},{"location":"roteiro1/#product-api","title":"PRODUCT API","text":"<p>Feito por: Lucas Abatepietro</p>"},{"location":"roteiro1/#arquitetura","title":"Arquitetura","text":"<pre><code>flowchart LR\n    subgraph api [Trusted Layer]\n        direction TB\n        gateway --&gt; account\n        gateway --&gt; auth\n        account --&gt; db[(Database)]\n        auth --&gt; account\n        gateway --&gt; product:::red\n        gateway --&gt; order\n        product --&gt; db\n        order --&gt; db\n        order --&gt; product\n    end\n    internet((Internet)) --&gt;|Request| gateway\n\n    classDef red fill:#fcc,stroke:#c00,stroke-width:2px;\n</code></pre>"},{"location":"roteiro1/#tarefas","title":"Tarefas","text":"<ol> <li> <p>Implementar um microservi\u00e7o PRODUCT que contenha:</p> </li> <li> <p><code>POST /product</code>: cria um produto</p> </li> <li><code>GET /product</code>: retorna todos os produtos</li> <li><code>GET /product/{id}</code>: retorna um produto pelo <code>id</code></li> <li> <p><code>DELETE /product/{id}</code>: deleta um produto dado um <code>id</code></p> </li> <li> <p>O servi\u00e7o foi implementado em Java, utilizando:</p> </li> <li>Spring Boot</li> <li>Spring Data JPA</li> <li>Spring Cloud OpenFeign para comunica\u00e7\u00e3o</li> <li>Banco de dados: PostgreSQL</li> </ol>"},{"location":"roteiro1/#endpoints-implementados","title":"Endpoints Implementados","text":"<p>Foram implementados os seguintes endpoints com request body e response da seguinte forma:</p>"},{"location":"roteiro1/#post-product","title":"POST /product","text":"<p>Cria um novo produto.</p> Request <pre><code>{\n  \"name\": \"Milho\",\n  \"price\": 69,\n  \"unit\": \"Ton\"\n}\n</code></pre> Response <pre><code>{\n  \"id\": \"generated-uuid\",\n  \"name\": \"Milho\",\n  \"price\": 69,\n  \"unit\": \"Ton\"\n}\n</code></pre> <pre><code>Response code: 201 (Created)\n</code></pre>"},{"location":"roteiro1/#get-product","title":"GET /product","text":"<p>Lista todos os produtos.</p> Response 200 <pre><code>[\n  {\n    \"id\": \"0195abfb-7074-73a9-9d26-b4b9fbaab0a8\",\n    \"name\": \"Milho\",\n    \"price\": 69,\n    \"unit\": \"Ton\"\n  },\n  {\n    \"id\": \"0195abfe-e416-7052-be3b-27cdaf12a984\",\n    \"name\": \"Queijadinha\",\n    \"price\": 0.62,\n    \"unit\": \"g\"\n  }\n]\n</code></pre> <pre><code>Response code: 200 (OK)\n</code></pre>"},{"location":"roteiro1/#get-productid","title":"GET /product/{id}","text":"<p>Pega um produto pelo ID.</p> Response 200 <pre><code>{\n  \"id\": \"0195abfb-7074-73a9-9d26-b4b9fbaab0a8\",\n  \"name\": \"Milho\",\n  \"price\": 69,\n  \"unit\": \"Ton\"\n}\n</code></pre> <pre><code>Response code: 200 (OK)\n</code></pre>"},{"location":"roteiro1/#delete-productid","title":"DELETE /product/{id}","text":"<p>Deleta um produto pelo ID.</p> Response <pre><code>Response code: 204 (No Content)\n</code></pre> <pre><code># Sem corpo de resposta.\n</code></pre>"},{"location":"roteiro1/#estrutura-do-projeto","title":"Estrutura do Projeto","text":""},{"location":"roteiro1/#product","title":"Product","text":"<pre><code>\ud83d\udcc1 api/\n\u2514\u2500\u2500 \ud83d\udcc1 product/\n    \u251c\u2500\u2500 \ud83d\udcc1 src/\n    \u2502   \u2514\u2500\u2500 \ud83d\udcc1 main/\n    \u2502       \u2514\u2500\u2500 \ud83d\udcc1 java/\n    \u2502           \u2514\u2500\u2500 \ud83d\udcc1 store/\n    \u2502               \u2514\u2500\u2500 \ud83d\udcc1 product/\n    \u2502                   \u251c\u2500\u2500 \ud83d\udcc4 ProductCtrl.java\n    \u2502                   \u251c\u2500\u2500 \ud83d\udcc4 ProductIn.java\n    \u2502                   \u2514\u2500\u2500 \ud83d\udcc4 ProductOut.java\n    \u2514\u2500\u2500 \ud83d\udcc4 pom.xml\n</code></pre>"},{"location":"roteiro1/#product-service","title":"Product-Service","text":"<pre><code>\ud83d\udcc1 api/\n\u2514\u2500\u2500 \ud83d\udcc1 product-service/\n    \u251c\u2500\u2500 \ud83d\udcc1 src/\n    \u2502   \u2514\u2500\u2500 \ud83d\udcc1 main/\n    \u2502       \u251c\u2500\u2500 \ud83d\udcc1 java/\n    \u2502       \u2502   \u2514\u2500\u2500 \ud83d\udcc1 store/\n    \u2502       \u2502       \u2514\u2500\u2500 \ud83d\udcc1 product/\n    \u2502       \u2502           \u251c\u2500\u2500 \ud83d\udcc4 Product.java\n    \u2502       \u2502           \u251c\u2500\u2500 \ud83d\udcc4 ProductApp.java\n    \u2502       \u2502           \u251c\u2500\u2500 \ud83d\udcc4 ProductModel.java\n    \u2502       \u2502           \u251c\u2500\u2500 \ud83d\udcc4 ProductParser.java\n    \u2502       \u2502           \u251c\u2500\u2500 \ud83d\udcc4 ProductRepo.java\n    \u2502       \u2502           \u251c\u2500\u2500 \ud83d\udcc4 ProductReso.java\n    \u2502       \u2502           \u2514\u2500\u2500 \ud83d\udcc4 ProductService.java\n    \u2502       \u2514\u2500\u2500 \ud83d\udcc1 resources/\n    \u2502           \u251c\u2500\u2500 \ud83d\udcc4 application.yaml\n    \u2502           \u2514\u2500\u2500 \ud83d\udcc1 db/\n    \u2502               \u2514\u2500\u2500 \ud83d\udcc1 migration/\n    \u2502                   \u251c\u2500\u2500 \ud83d\udcc4 schema.sql\n    \u2502                   \u2514\u2500\u2500 \ud83d\udcc4 table.sql\n    \u251c\u2500\u2500 \ud83d\udcc4 pom.xml\n    \u2514\u2500\u2500 \ud83d\udcc4 Dockerfile\n</code></pre>"},{"location":"roteiro1/#repositorios","title":"Reposit\u00f3rios","text":"<ul> <li>Product</li> <li>Product-Service</li> </ul>"},{"location":"roteiro1/#conclusao","title":"Conclus\u00e3o","text":"<p>Cada enxadada, uma minhoca. \ud83e\udeb1</p>"},{"location":"roteiro2/","title":"Order API","text":""},{"location":"roteiro2/#order-api","title":"ORDER API","text":"<p>Feito por: Lucas Abatepietro</p>"},{"location":"roteiro2/#arquitetura","title":"Arquitetura","text":"<pre><code>flowchart LR\n    subgraph api [Trusted Layer]\n        direction TB\n        gateway --&gt; account\n        gateway --&gt; auth\n        account --&gt; db[(Database)]\n        auth --&gt; account\n        gateway --&gt; order:::red\n        gateway --&gt; order\n        order --&gt; db\n        order --&gt; db\n        order --&gt; order\n    end\n    internet((Internet)) --&gt;|Request| gateway\n\n    classDef red fill:#fcc,stroke:#c00,stroke-width:2px;\n</code></pre>"},{"location":"roteiro2/#tarefas","title":"Tarefas","text":"<p>Implementar um microservi\u00e7o ORDER que tenha os seguintes requisitos:</p> <ul> <li><code>POST /order</code>: cria um pedido</li> <li><code>GET /order</code>: lista todos os pedidos</li> <li><code>GET /order/{id}</code>: busca pedido por ID</li> </ul> <p>Este servi\u00e7o segue o padr\u00e3o adotado no projeto: interface (<code>order</code>) e service (<code>order-service</code>), posicionados atr\u00e1s do gateway e protegidos por JWT.</p>"},{"location":"roteiro2/#estrutura-do-projeto","title":"Estrutura do Projeto","text":""},{"location":"roteiro2/#order","title":"Order","text":"<pre><code>\ud83d\udcc1 api/\n\u2514\u2500\u2500 \ud83d\udcc1 order/\n    \u251c\u2500\u2500 \ud83d\udcc1 src/\n    \u2502   \u2514\u2500\u2500 \ud83d\udcc1 main/\n    \u2502       \u2514\u2500\u2500 \ud83d\udcc1 java/\n    \u2502           \u2514\u2500\u2500 \ud83d\udcc1 store/\n    \u2502               \u2514\u2500\u2500 \ud83d\udcc1 order/\n    \u2502                   \u251c\u2500\u2500 \ud83d\udcc4 OrderController.java\n    \u2502                   \u251c\u2500\u2500 \ud83d\udcc4 OrderIn.java\n    \u2502                   \u251c\u2500\u2500 \ud83d\udcc4 OrderOut.java\n    \u2502                   \u251c\u2500\u2500 \ud83d\udcc4 OrderItemIn.java\n    \u2502                   \u2514\u2500\u2500 \ud83d\udcc4 OrderItemOut.java\n    \u2514\u2500\u2500 \ud83d\udcc4 pom.xml\n</code></pre>"},{"location":"roteiro2/#order-service","title":"Order-Service","text":"<pre><code>\ud83d\udcc1 api/\n\u2514\u2500\u2500 \ud83d\udcc1 order-service/\n    \u251c\u2500\u2500 \ud83d\udcc1 src/\n    \u2502   \u2514\u2500\u2500 \ud83d\udcc1 main/\n    \u2502       \u251c\u2500\u2500 \ud83d\udcc1 java/\n    \u2502       \u2502   \u2514\u2500\u2500 \ud83d\udcc1 store/\n    \u2502       \u2502       \u2514\u2500\u2500 \ud83d\udcc1 order/\n    \u2502       \u2502           \u251c\u2500\u2500 \ud83d\udcc4 Order.java\n    \u2502       \u2502           \u251c\u2500\u2500 \ud83d\udcc4 OrderItem.java\n    \u2502       \u2502           \u251c\u2500\u2500 \ud83d\udcc4 OrderApp.java\n    \u2502       \u2502           \u251c\u2500\u2500 \ud83d\udcc4 OrderModel.java\n    \u2502       \u2502           \u251c\u2500\u2500 \ud83d\udcc4 OrderParser.java\n    \u2502       \u2502           \u251c\u2500\u2500 \ud83d\udcc4 OrderRepo.java\n    \u2502       \u2502           \u251c\u2500\u2500 \ud83d\udcc4 OrderResource.java\n    \u2502       \u2502           \u251c\u2500\u2500 \ud83d\udcc4 OrderService.java\n    \u2502       \u2502           \u2514\u2500\u2500 \ud83d\udcc4 FeignAuthInter.java\n    \u2502       \u2514\u2500\u2500 \ud83d\udcc1 resources/\n    \u2502           \u251c\u2500\u2500 \ud83d\udcc4 application.yaml\n    \u2502           \u2514\u2500\u2500 \ud83d\udcc1 db/\n    \u2502               \u2514\u2500\u2500 \ud83d\udcc1 migration/\n    \u2502                   \u251c\u2500\u2500 \ud83d\udcc4 schema.sql\n    \u2502                   \u251c\u2500\u2500 \ud83d\udcc4 create_table.sql\n    \u2502                   \u2514\u2500\u2500 \ud83d\udcc4 orderitem.sql\n    \u251c\u2500\u2500 \ud83d\udcc4 pom.xml\n    \u2514\u2500\u2500 \ud83d\udcc4 Dockerfile\n</code></pre>"},{"location":"roteiro2/#endpoints-implementados","title":"Endpoints Implementados","text":""},{"location":"roteiro2/#post-order","title":"POST /order","text":"<p>Cria um novo pedido.</p> Request <pre><code>{\n  \"items\": [\n    {\n      \"idProduct\": \"0195abfb-7074-73a9-9d26-b4b9fbaab0a8\",\n      \"quantity\": 2\n    },\n    {\n      \"idProduct\": \"0195abfe-e416-7052-be3b-27cdaf12a984\",\n      \"quantity\": 1\n    }\n  ]\n}\n</code></pre> Response <pre><code>{\n  \"id\": \"0195ac33-73e5-7cb3-90ca-7b5e7e549569\",\n  \"date\": \"2025-09-01T12:30:00\",\n  \"items\": [\n    {\n      \"id\": \"01961b9a-bca2-78c4-9be1-7092b261f217\",\n      \"product\": { \"id\": \"0195abfb-7074-73a9-9d26-b4b9fbaab0a8\" },\n      \"quantity\": 2,\n      \"total\": 20.24\n    },\n    {\n      \"id\": \"01961b9b-08fd-76a5-8508-cdb6cd5c27ab\",\n      \"product\": { \"id\": \"0195abfe-e416-7052-be3b-27cdaf12a984\" },\n      \"quantity\": 10,\n      \"total\": 6.2\n    }\n  ],\n  \"total\": 26.44\n}\n</code></pre> <pre><code>Response code: 201 (Created)\nResponse code: 400 (Bad Request) \u2014 se o produto n\u00e3o existir.\n</code></pre>"},{"location":"roteiro2/#get-order","title":"GET /order","text":"<p>Lista todos os pedidos.</p> Response 200 <pre><code>[\n  {\n    \"id\": \"0195ac33-73e5-7cb3-90ca-7b5e7e549569\",\n    \"date\": \"2025-09-01T12:30:00\",\n    \"total\": 26.44\n  },\n  {\n    \"id\": \"0195ac33-cbbd-7a6e-a15b-b85402cf143f\",\n    \"date\": \"2025-10-09T03:21:57\",\n    \"total\": 18.6\n  }\n]\n</code></pre> <pre><code>Response code: 200 (OK)\n</code></pre>"},{"location":"roteiro2/#get-orderid","title":"GET /order/{id}","text":"<p>Busca pedido pelo ID.</p> Response 200 <pre><code>{\n  \"id\": \"0195ac33-73e5-7cb3-90ca-7b5e7e549569\",\n  \"date\": \"2025-09-01T12:30:00\",\n  \"items\": [\n    {\n      \"id\": \"01961b9a-bca2-78c4-9be1-7092b261f217\",\n      \"product\": { \"id\": \"0195abfb-7074-73a9-9d26-b4b9fbaab0a8\" },\n      \"quantity\": 2,\n      \"total\": 20.24\n    },\n    {\n      \"id\": \"01961b9b-08fd-76a5-8508-cdb6cd5c27ab\",\n      \"product\": { \"id\": \"0195abfe-e416-7052-be3b-27cdaf12a984\" },\n      \"quantity\": 10,\n      \"total\": 6.2\n    }\n  ],\n  \"total\": 26.44\n}\n</code></pre> <pre><code>Response code: 200 (OK)\nResponse code: 404 (Not Found) \u2014 se o pedido n\u00e3o pertencer ao usu\u00e1rio atual.\n</code></pre>"},{"location":"roteiro2/#repositorios","title":"Reposit\u00f3rios","text":"<ul> <li>Order</li> <li>Order-Service</li> </ul>"},{"location":"roteiro2/#conclusao","title":"Conclus\u00e3o","text":"<p>Cada enxadada, uma minhoca. \ud83e\udeb1</p>"},{"location":"roteiro3/","title":"Exchange API","text":""},{"location":"roteiro3/#exchange-api","title":"EXCHANGE API","text":"<p>Feito por: Lucas Abatepietro</p>"},{"location":"roteiro3/#arquitetura","title":"Arquitetura","text":"<pre><code>flowchart LR\n    subgraph api [Trusted Layer]\n        direction TB\n        gateway --&gt; account\n        gateway --&gt; auth\n        account --&gt; db[(Database)]\n        auth --&gt; account\n        gateway --&gt; exchange:::red\n        gateway --&gt; order\n        exchange --&gt; db\n        order --&gt; db\n        order --&gt; exchange\n    end\n    internet((Internet)) --&gt;|Request| gateway\n\n    classDef red fill:#fcc,stroke:#c00,stroke-width:2px;\n</code></pre>"},{"location":"roteiro3/#tarefas","title":"Tarefas","text":"<p>Implementar um microservi\u00e7o desenvolvido em FastAPI, respons\u00e1vel por consultar um provedor externo de c\u00e2mbio e aplicar regras de spread.</p> <ul> <li>A API utiliza o ExchangeRate-API para obter o pre\u00e7o atual das trocas entre moedas (c\u00e2mbio).</li> </ul>"},{"location":"roteiro3/#estrutura-do-projeto","title":"Estrutura do Projeto","text":""},{"location":"roteiro3/#exchange-service","title":"Exchange-Service","text":"<pre><code>\ud83d\udcc1 api/\n\u2514\u2500\u2500 \ud83d\udcc1 exchange-service/\n    \u251c\u2500\u2500 \ud83d\udcc1 app/\n    \u2502   \u251c\u2500\u2500 \ud83d\udcc4 main.py\n    \u2502   \u251c\u2500\u2500 \ud83d\udcc4 auth.py\n    \u2502   \u251c\u2500\u2500 \ud83d\udcc4 config.py\n    \u2502   \u251c\u2500\u2500 \ud83d\udcc4 models.py\n    \u2502   \u2514\u2500\u2500 \ud83d\udcc4 rates.py\n    \u251c\u2500\u2500 \ud83d\udcc4 requirements.txt\n    \u2514\u2500\u2500 \ud83d\udcc4 Dockerfile\n</code></pre>"},{"location":"roteiro3/#endpoint-implementado","title":"Endpoint Implementado","text":""},{"location":"roteiro3/#get-exchangefromto","title":"GET /exchange/{from}/{to}","text":"<p>Retorna a taxa de c\u00e2mbio entre duas moedas.</p> Response <pre><code>{\n  \"sell\": 0.82,\n  \"buy\": 0.8,\n  \"date\": \"2021-09-01 14:23:42\",\n  \"id-account\": \"0195ae95-5be7-7dd3-b35d-7a7d87c404fb\"\n}\n</code></pre> <pre><code>Response code: 200 (OK)\n</code></pre>"},{"location":"roteiro3/#repositorios","title":"Reposit\u00f3rios","text":"<ul> <li>Exchange-Service</li> </ul>"},{"location":"roteiro3/#conclusao","title":"Conclus\u00e3o","text":"<p>Cada enxadada, uma minhoca. \ud83e\udeb1</p>"},{"location":"roteiro4/","title":"Jenkins","text":""},{"location":"roteiro4/#jenkins","title":"JENKINS","text":"<p>A orquestra\u00e7\u00e3o da esteira de CI/CD do dom\u00ednio store \u00e9 realizada pelo Jenkins, que executa dois tipos principais de pipelines:</p>"},{"location":"roteiro4/#1-pipelines-de-interfaces","title":"1. Pipelines de Interfaces","text":"<p>(Ex.: account, auth, product, order, \u2026)</p> <ul> <li>Respons\u00e1veis por empacotar artefatos e contratos utilizados por outros m\u00f3dulos.</li> <li>N\u00e3o geram nem publicam imagens Docker.</li> </ul>"},{"location":"roteiro4/#2-pipelines-de-servicos","title":"2. Pipelines de Servi\u00e7os","text":"<p>(Ex.: account-service, auth-service, product-service, order-service, gateway-service, \u2026)</p> <ul> <li>Realizam o build da aplica\u00e7\u00e3o (Java ou Python).</li> <li>Executam o build e push de imagens Docker para o Docker Hub.</li> <li>Podem acionar pipelines de depend\u00eancia, como a compila\u00e7\u00e3o pr\u00e9via da interface correspondente.</li> </ul>"},{"location":"roteiro4/#status-atual-do-pipeline","title":"Status Atual do Pipeline","text":""},{"location":"roteiro4/#estrutura-do-projeto","title":"Estrutura do Projeto","text":"<pre><code>\ud83d\udcc1 api/\n\u251c\u2500\u2500 \ud83d\udcc1 jenkins/\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 compose.yaml\n\u2502   \u2514\u2500\u2500 \ud83d\udcc1 config/\n\u251c\u2500\u2500 \ud83d\udcc1 account/\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 Jenkinsfile\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 Dockerfile\n\u2502   \u2514\u2500\u2500 \ud83d\udcc1 src/\n\u251c\u2500\u2500 \ud83d\udcc1 auth-service/\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 Jenkinsfile\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 Dockerfile\n\u2502   \u2514\u2500\u2500 \ud83d\udcc1 src/\n\u251c\u2500\u2500 \ud83d\udcc1 gateway-service/\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 Jenkinsfile\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 Dockerfile\n\u2502   \u2514\u2500\u2500 \ud83d\udcc1 src/\n\u251c\u2500\u2500 \ud83d\udcc1 product/\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 Jenkinsfile\n\u2502   \u2514\u2500\u2500 \ud83d\udcc1 src/\n\u2514\u2500\u2500 \ud83d\udcc1 order/\n    \u251c\u2500\u2500 \ud83d\udcc4 Jenkinsfile\n    \u2514\u2500\u2500 \ud83d\udcc1 src/\n</code></pre>"},{"location":"roteiro4/#jenkins-setup","title":"Jenkins Setup","text":"<pre><code># docker compose up -d --build --force-recreate\nname: ops\n\nservices:\n  jenkins:\n    container_name: jenkins\n    build:\n      dockerfile_inline: |\n        FROM jenkins/jenkins:jdk21\n        USER root\n\n        # Install tools\n        RUN apt-get update &amp;&amp; apt-get install -y lsb-release iputils-ping maven\n\n        # Install Docker\n        RUN curl -fsSLo /usr/share/keyrings/docker-archive-keyring.asc           https://download.docker.com/linux/debian/gpg\n        RUN echo \"deb [arch=$(dpkg --print-architecture)           signed-by=/usr/share/keyrings/docker-archive-keyring.asc]           https://download.docker.com/linux/debian           $(lsb_release -cs) stable\" &gt; /etc/apt/sources.list.d/docker.list\n        RUN apt-get update &amp;&amp; apt-get install -y docker-ce\n\n        # Install kubectl\n        RUN apt-get install -y apt-transport-https ca-certificates curl\n        RUN curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.30/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg\n        RUN chmod 644 /etc/apt/keyrings/kubernetes-apt-keyring.gpg\n        RUN echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.30/deb/ /' | tee /etc/apt/sources.list.d/kubernetes.list\n        RUN chmod 644 /etc/apt/sources.list.d/kubernetes.list\n        RUN apt-get update &amp;&amp; apt-get install -y kubectl\n\n        RUN usermod -aG docker jenkins\n    ports:\n      - 9080:8080\n    volumes:\n      - ${CONFIG:-./config}/jenkins:/var/jenkins_home\n      - /var/run/docker.sock:/var/run/docker.sock\n    restart: always\n</code></pre>"},{"location":"roteiro4/#exemplo-de-pipeline-de-servico","title":"Exemplo de Pipeline de Servi\u00e7o","text":"<p>Jenkinsfile para <code>account-service</code>:</p> <pre><code>pipeline {\n    agent any\n    environment {\n        SERVICE = 'account'\n        NAME = \"luabatepietro/${env.SERVICE}\"\n    }\n    stages {\n        stage('Dependecies') {\n            steps {\n                build job: 'account', wait: true\n            }\n        }\n        stage('Build') {\n            steps {\n                sh 'mvn -B -DskipTests clean package'\n            }\n        }\n        stage('Build &amp; Push Image') {\n            steps {\n                withCredentials([usernamePassword(\n                    credentialsId: 'dockerhub-credential',\n                    usernameVariable: 'USERNAME',\n                    passwordVariable: 'TOKEN')])\n                {\n                    sh \"docker login -u $USERNAME -p $TOKEN\"\n                    sh \"docker buildx create --use --platform=linux/arm64,linux/amd64 --node multi-platform-builder-${env.SERVICE} --name multi-platform-builder-${env.SERVICE}\"\n                    sh \"docker buildx build --platform=linux/arm64,linux/amd64 --push --tag ${env.NAME}:latest --tag ${env.NAME}:${env.BUILD_ID} -f Dockerfile .\"\n                    sh \"docker buildx rm --force multi-platform-builder-${env.SERVICE}\"\n                }\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"roteiro4/#exemplo-de-pipeline-de-contrato","title":"Exemplo de Pipeline de Contrato","text":"<p>Jenkinsfile para <code>contract</code>:</p> <pre><code>pipeline {\n    agent any\n\n    stages {\n        stage('Build') {\n            steps {\n                sh 'mvn -B -DskipTests clean install'\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"roteiro4/#conclusao","title":"Conclus\u00e3o","text":"<p>Cada enxadada, uma minhoca. \ud83e\udeb1</p>"},{"location":"roteiro5/","title":"K8S","text":""},{"location":"roteiro5/#kubernetes","title":"KUBERNETES","text":""},{"location":"roteiro5/#repositorios-utilizados","title":"Reposit\u00f3rios Utilizados","text":"Reposit\u00f3rio Descri\u00e7\u00e3o Account-Service Servi\u00e7o de contas de usu\u00e1rio Auth-Service Servi\u00e7o de autentica\u00e7\u00e3o Gateway-Service API Gateway Product-Service Servi\u00e7o de produtos Order-Service Servi\u00e7o de pedidos Exchange-Service Servi\u00e7o de c\u00e2mbio \u2014 Banco de dados (Postgres, gitignore)"},{"location":"roteiro5/#estrutura-do-projeto","title":"Estrutura do Projeto","text":"<pre><code>\ud83d\udcc1 api/\n\u251c\u2500\u2500 \ud83d\udcc1 account-service/\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 Jenkinsfile\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 Dockerfile\n\u2502   \u251c\u2500\u2500 \ud83d\udcc1 k8s/\n\u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc4 k8s.yaml\n\u2502   \u2514\u2500\u2500 \ud83d\udcc1 src/\n\u251c\u2500\u2500 \ud83d\udcc1 auth-service/\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 Jenkinsfile\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 Dockerfile\n\u2502   \u251c\u2500\u2500 \ud83d\udcc1 k8s/\n\u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc4 k8s.yaml\n\u2502   \u2514\u2500\u2500 \ud83d\udcc1 src/\n\u251c\u2500\u2500 \ud83d\udcc1 gateway-service/\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 Jenkinsfile\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 Dockerfile\n\u2502   \u251c\u2500\u2500 \ud83d\udcc1 k8s/\n\u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc4 k8s.yaml\n\u2502   \u2514\u2500\u2500 \ud83d\udcc1 src/\n\u251c\u2500\u2500 \ud83d\udcc1 product-service/\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 Jenkinsfile\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 Dockerfile\n\u2502   \u251c\u2500\u2500 \ud83d\udcc1 k8s/\n\u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc4 k8s.yaml\n\u2502   \u2514\u2500\u2500 \ud83d\udcc1 src/\n\u2514\u2500\u2500 \ud83d\udcc1 order-service/\n    \u251c\u2500\u2500 \ud83d\udcc4 Jenkinsfile\n    \u251c\u2500\u2500 \ud83d\udcc4 Dockerfile\n    \u251c\u2500\u2500 \ud83d\udcc1 k8s/\n    \u2502   \u2514\u2500\u2500 \ud83d\udcc4 k8s.yaml\n    \u2514\u2500\u2500 \ud83d\udcc1 src/\n</code></pre>"},{"location":"roteiro5/#configuracoes-do-kubernetes","title":"Configura\u00e7\u00f5es do Kubernetes","text":"<p>Os servi\u00e7os foram configurados com Deployments e Services separados, utilizando boas pr\u00e1ticas de isolamento e gerenciamento de vari\u00e1veis de ambiente por meio de ConfigMaps e Secrets.</p> Account Service <pre><code># k8s/k8s.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: account\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: account\n  template:\n    metadata:\n      labels:\n        app: account\n    spec:\n      containers:\n        - name: account\n          image: luabatepietro/account:latest\n          imagePullPolicy: Always\n          ports:\n            - containerPort: 8080\n          env:\n            - name: POSTGRES_DB\n              valueFrom:\n                configMapKeyRef:\n                  name: postgres-configmap\n                  key: POSTGRES_DB\n            - name: DATABASE_USERNAME\n              valueFrom:\n                secretKeyRef:\n                  name: postgres-secrets\n                  key: POSTGRES_USER\n            - name: DATABASE_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: postgres-secrets\n                  key: POSTGRES_PASSWORD\n            - name: DATABASE_URL\n              value: \"jdbc:postgresql://postgres:5432/$(POSTGRES_DB)\"\n          resources:\n            requests:\n              memory: \"200Mi\"\n              cpu: \"50m\"\n            limits:\n              memory: \"300Mi\"\n              cpu: \"200m\"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: account\n  labels:\n    app: account\nspec:\n  type: ClusterIP\n  ports:\n    - port: 80\n      protocol: TCP\n      targetPort: 8080\n  selector:\n    app: account\n</code></pre> Auth Service <pre><code># k8s/k8s.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: auth\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: auth\n  template:\n    metadata:\n      labels:\n        app: auth\n    spec:\n      containers:\n        - name: auth\n          image: luabatepietro/auth:latest\n          imagePullPolicy: Always\n          ports:\n            - containerPort: 8080\n          env:\n            - name: POSTGRES_DB\n              valueFrom:\n                configMapKeyRef:\n                  name: postgres-configmap\n                  key: POSTGRES_DB\n            - name: DATABASE_USERNAME\n              valueFrom:\n                secretKeyRef:\n                  name: postgres-secrets\n                  key: POSTGRES_USER\n            - name: DATABASE_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: postgres-secrets\n                  key: POSTGRES_PASSWORD\n            - name: DATABASE_URL\n              value: \"jdbc:postgresql://postgres:5432/$(POSTGRES_DB)\"\n          resources:\n            requests:\n              memory: \"200Mi\"\n              cpu: \"50m\"\n            limits:\n              memory: \"300Mi\"\n              cpu: \"200m\"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: auth\n  labels:\n    app: auth\nspec:\n  type: ClusterIP\n  ports:\n    - port: 80\n      protocol: TCP\n      targetPort: 8080\n  selector:\n    app: auth\n</code></pre> Gateway Service <pre><code># k8s/k8s.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: gateway\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gateway\n  template:\n    metadata:\n      labels:\n        app: gateway\n    spec:\n      containers:\n        - name: gateway\n          image: luabatepietro/gateway:latest\n          imagePullPolicy: Always\n          ports:\n            - containerPort: 8080\n          resources:\n            requests:\n              memory: \"200Mi\"\n              cpu: \"50m\"\n            limits:\n              memory: \"300Mi\"\n              cpu: \"200m\"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: gateway\n  labels:\n    app: gateway\nspec:\n  type: LoadBalancer\n  ports:\n    - port: 80\n      protocol: TCP\n      targetPort: 8080\n  selector:\n    app: gateway\n</code></pre> Product Service <pre><code># k8s/k8s.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: product\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: product\n  template:\n    metadata:\n      labels:\n        app: product\n    spec:\n      containers:\n        - name: product\n          image: luabatepietro/product:latest\n          imagePullPolicy: Always\n          ports:\n            - containerPort: 8080\n          env:\n            - name: POSTGRES_DB\n              valueFrom:\n                configMapKeyRef:\n                  name: postgres-configmap\n                  key: POSTGRES_DB\n            - name: DATABASE_USERNAME\n              valueFrom:\n                secretKeyRef:\n                  name: postgres-secrets\n                  key: POSTGRES_USER\n            - name: DATABASE_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: postgres-secrets\n                  key: POSTGRES_PASSWORD\n            - name: DATABASE_URL\n              value: \"jdbc:postgresql://postgres:5432/$(POSTGRES_DB)\"\n            - name: SPRING_CACHE_TYPE\n              value: redis\n            - name: SPRING_DATA_REDIS_HOST\n              value: redis\n            - name: SPRING_DATA_REDIS_PORT\n              value: \"6379\"\n          resources:\n            requests:\n              memory: \"200Mi\"\n              cpu: \"50m\"\n            limits:\n              memory: \"300Mi\"\n              cpu: \"200m\"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: product\n  labels:\n    app: product\nspec:\n  type: ClusterIP\n  ports:\n    - port: 80\n      protocol: TCP\n      targetPort: 8080\n  selector:\n    app: product\n</code></pre> Order Service <pre><code># k8s/k8s.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: order\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: order\n  template:\n    metadata:\n      labels:\n        app: order\n    spec:\n      containers:\n        - name: order\n          image: luabatepietro/order:latest\n          imagePullPolicy: Always\n          ports:\n            - containerPort: 8080\n          env:\n            - name: POSTGRES_DB\n              valueFrom:\n                configMapKeyRef:\n                  name: postgres-configmap\n                  key: POSTGRES_DB\n            - name: DATABASE_USERNAME\n              valueFrom:\n                secretKeyRef:\n                  name: postgres-secrets\n                  key: POSTGRES_USER\n            - name: DATABASE_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: postgres-secrets\n                  key: POSTGRES_PASSWORD\n            - name: DATABASE_URL\n              value: \"jdbc:postgresql://postgres:5432/$(POSTGRES_DB)\"\n          resources:\n            requests:\n              memory: \"200Mi\"\n              cpu: \"50m\"\n            limits:\n              memory: \"300Mi\"\n              cpu: \"200m\"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: order\n  labels:\n    app: order\nspec:\n  type: ClusterIP\n  ports:\n    - port: 80\n      protocol: TCP\n      targetPort: 8080\n  selector:\n    app: order\n</code></pre>"},{"location":"roteiro5/#foto","title":"Foto","text":""},{"location":"roteiro6/","title":"Bottlenecks","text":""},{"location":"roteiro6/#bottlenecks-escalabilidade-e-desempenho","title":"Bottlenecks \u2013 Escalabilidade e Desempenho","text":"<p>Este documento consolida as estrat\u00e9gias de balanceamento de carga e cache distribu\u00eddo utilizadas no ecossistema store-api, respons\u00e1veis por mitigar gargalos de desempenho e garantir resili\u00eancia, disponibilidade e escalabilidade no ambiente Kubernetes (AWS EKS).</p>"},{"location":"roteiro6/#1-load-balancer-aws-eks","title":"1. Load Balancer (AWS EKS)","text":""},{"location":"roteiro6/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>O Gateway Service atua como ponto de entrada \u00fanico para todas as requisi\u00e7\u00f5es externas ao cluster. Ele \u00e9 configurado com um Service Kubernetes do tipo <code>LoadBalancer</code>, instruindo o EKS (Elastic Kubernetes Service) a provisionar automaticamente um Elastic Load Balancer (ELB) na AWS.</p> <p>Essa camada \u00e9 essencial para distribuir o tr\u00e1fego de forma equilibrada entre as inst\u00e2ncias dos microservi\u00e7os, garantindo alta disponibilidade e evitando sobrecarga em um \u00fanico n\u00f3.</p>"},{"location":"roteiro6/#fluxo-de-trafego","title":"Fluxo de Tr\u00e1fego","text":"<pre><code>Usu\u00e1rio\n   \u2193\nLoad Balancer\n   \u2193\nGateway Service\n   \u2193\n \u251c\u2500\u2500 Account\n \u251c\u2500\u2500 Auth\n \u251c\u2500\u2500 Order\n \u251c\u2500\u2500 Product\n \u2514\u2500\u2500 Exchange\n</code></pre>"},{"location":"roteiro6/#configuracao-do-gateway","title":"Configura\u00e7\u00e3o do Gateway","text":"<p>O Gateway Service \u00e9 implementado com recursos Kubernetes do tipo Deployment e Service, respons\u00e1veis por expor o ponto de entrada p\u00fablico e rotear as requisi\u00e7\u00f5es internas.</p> <p>Para detalhes completos sobre o deployment e o service, consulte a documenta\u00e7\u00e3o da Gateway API.</p> <ol> <li>Cache Distribu\u00eddo (Redis)</li> <li>Vis\u00e3o Geral<ul> <li>O Product Service utiliza o Redis como camada de cache distribu\u00eddo para reduzir a lat\u00eancia e o n\u00famero de leituras diretas no banco de dados PostgreSQL.</li> </ul> </li> </ol> <p>Essa abordagem permite que respostas a consultas recorrentes sejam entregues rapidamente, diminuindo o uso de recursos e o tempo de resposta percebido pelo usu\u00e1rio final.</p> <p>O cache \u00e9 implementado por meio da abstra\u00e7\u00e3o nativa do Spring Boot Cache, com gerenciamento centralizado pelo RedisCacheManager.</p>"},{"location":"roteiro6/#arquitetura-do-cache","title":"Arquitetura do Cache","text":"<pre><code>Copiar c\u00f3digo\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          \u2502 Client / Gateway   \u2502\n          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n                    \u25bc\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          \u2502 Product Service    \u2502\n          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n          \u2502 Cache Hit  \u2192 Redis \u2502\n          \u2502 Cache Miss \u2192 PostgreSQL \u2502\n          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"roteiro6/#estrategia-de-cache","title":"Estrat\u00e9gia de Cache","text":"<p>Tipo de Opera\u00e7\u00e3o    Estrat\u00e9gia de Cache TTL findAll()   Cache da lista completa (products-list) 2 minutos findById(id)    Cache individual (product-by-id)    10 minutos create() / delete() Evict autom\u00e1tico das chaves afetadas</p> <p>A implementa\u00e7\u00e3o do cache \u00e9 feita com as anota\u00e7\u00f5es @Cacheable e @CacheEvict, definindo o comportamento de leitura e invalida\u00e7\u00e3o dos dados. Para mais detalhes, consulte a documenta\u00e7\u00e3o da Product API.</p>"},{"location":"roteiro6/#redis-no-kubernetes","title":"Redis no Kubernetes","text":""},{"location":"roteiro6/#implantacao","title":"Implanta\u00e7\u00e3o","text":"<p>O Redis \u00e9 executado em um Deployment dedicado dentro do cluster, com exposi\u00e7\u00e3o interna por meio de um Service do tipo ClusterIP, acess\u00edvel apenas por outros microservi\u00e7os.</p> <pre><code>Copiar c\u00f3digo\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: redis\n  template:\n    metadata:\n      labels:\n        app: redis\n    spec:\n      containers:\n        - name: redis\n          image: redis:latest\n          ports:\n            - containerPort: 6379\n          resources:\n            requests:\n              memory: \"64Mi\"\n              cpu: \"50m\"\n            limits:\n              memory: \"128Mi\"\n              cpu: \"100m\"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: redis\nspec:\n  type: ClusterIP\n  ports:\n    - port: 6379\n      targetPort: 6379\n  selector:\n    app: redis\nO servi\u00e7o Redis \u00e9 resolvido via DNS interno (redis.store.svc.cluster.local) e acessado pelos microservi\u00e7os utilizando:\n</code></pre>"},{"location":"roteiro6/#a-arquitetura-de-bottlenecks-integra-tres-pilares-essenciais","title":"A arquitetura de Bottlenecks integra tr\u00eas pilares essenciais:","text":"<ul> <li> <p>Elastic Load Balancer (ELB)</p> <ul> <li>distribui\u00e7\u00e3o inteligente de tr\u00e1fego no n\u00edvel de entrada, com resili\u00eancia autom\u00e1tica no EKS.</li> </ul> </li> <li> <p>Redis Cache</p> <ul> <li>camada de cache eficiente que reduz a lat\u00eancia e o consumo de banco de dados.</li> <li>ClusterIP Interno \u2014 comunica\u00e7\u00e3o segura entre microservi\u00e7os, isolada do tr\u00e1fego externo.</li> </ul> </li> </ul> <p>Essas estrat\u00e9gias combinadas resultam em: 1. Redu\u00e7\u00e3o significativa da lat\u00eancia m\u00e9dia das APIs.</p> <ol> <li> <p>Maior resili\u00eancia em cen\u00e1rios de pico de carga.</p> </li> <li> <p>Escalabilidade horizontal automatizada.</p> </li> </ol>"},{"location":"roteiro7/","title":"CI/CD","text":""},{"location":"roteiro7/#cicd-com-jenkins","title":"CI/CD Com Jenkins","text":"<ul> <li>Desenvolvido por:<ul> <li>Lucas Abatepietro</li> <li>Marcelo Alonso</li> <li>Henrique Bucci</li> </ul> </li> </ul>"},{"location":"roteiro7/#como-implementamos-isso","title":"Como implementamos isso?","text":""},{"location":"roteiro7/#1-composeyaml-do-jenkinsfile","title":"1. <code>compose.yaml</code> do Jenkinsfile","text":"<p>tivemos que mudar o <code>compose.yaml</code> do Jenkinsfile para instalar a aws corretamente, sendo poss\u00edvel conectar com nosso servi\u00e7o. Ficando da seguinte forma:</p> <pre><code># docker compose up -d --build --force-recreate\nname: ops\n\nservices:\n\n  jenkins:\n    container_name: jenkins\n    build:\n      dockerfile_inline: |\n        FROM jenkins/jenkins:jdk21\n        USER root\n\n        # Install tools\n        RUN apt-get update &amp;&amp; apt-get install -y lsb-release iputils-ping maven\n\n        # Install Docker\n        RUN curl -fsSLo /usr/share/keyrings/docker-archive-keyring.asc \\\n          https://download.docker.com/linux/debian/gpg\n        RUN echo \"deb [arch=$(dpkg --print-architecture) \\\n          signed-by=/usr/share/keyrings/docker-archive-keyring.asc] \\\n          https://download.docker.com/linux/debian \\\n          $(lsb_release -cs) stable\" &gt; /etc/apt/sources.list.d/docker.list\n        RUN apt-get update &amp;&amp; apt-get install -y docker-ce\n\n        # Install kubectl\n        RUN apt-get install -y apt-transport-https ca-certificates curl\n        RUN curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.30/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg\n        RUN chmod 644 /etc/apt/keyrings/kubernetes-apt-keyring.gpg\n        RUN echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.30/deb/ /' | tee /etc/apt/sources.list.d/kubernetes.list\n        RUN chmod 644 /etc/apt/sources.list.d/kubernetes.list\n        RUN apt-get update &amp;&amp; apt-get install -y kubectl\n\n        # Install AWS CLI\n        RUN apt-get install -y unzip\n        RUN curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\" &amp;&amp; \\\n            unzip awscliv2.zip &amp;&amp; \\\n            ./aws/install &amp;&amp; \\\n            rm -rf aws awscliv2.zip\n\n        RUN usermod -aG docker jenkins\n    ports:\n      - 9080:8080\n    volumes:\n      - ${CONFIG:-./config}/jenkins:/var/jenkins_home\n      - /var/run/docker.sock:/var/run/docker.sock\n    restart: always\n</code></pre>"},{"location":"roteiro7/#2-jenkinsfile-dos-servicos","title":"2. <code>Jenkinsfile</code> dos servi\u00e7os","text":"<p>Todos os servi\u00e7os tiveram a adi\u00e7\u00e3o de uma linha de codigo no Jenkins para que seja poss\u00edvel enviar para a aws, onde tivemos que passar na CREDENTIALS:</p> Credencial Vari\u00e1vel de Ambiente aws-access-key-id AWS_ACCESS_KEY_ID aws-secret-access-key AWS_SECRET_ACCESS_KEY aws-region AWS_REGION eks-cluster-name CLUSTER_NAME <p>Al\u00e9m dos CREDENTIALS adicionados. Al\u00e9m disso, tivemos que alterar o <code>Jenkinsfile</code> de todos os servi\u00e7os que ficaram da seguinte forma agora:</p> <pre><code>pipeline {\n    agent any\n    environment {\n        SERVICE = 'order'\n        NAME = \"luabatepietro/${env.SERVICE}\"\n    }\n    stages {\n        stage('Dependecies') {\n            steps {\n                build job: 'order', wait: true\n            }\n        }\n        stage('Build') { \n            steps {\n                sh 'mvn -B -DskipTests clean package'\n            }\n        }      \n        stage('Build &amp; Push Image') {\n            steps {\n                withCredentials([usernamePassword(\n                    credentialsId: 'dockerhub-credential',\n                    usernameVariable: 'USERNAME',\n                    passwordVariable: 'TOKEN')])\n                {\n                    sh \"docker login -u $USERNAME -p $TOKEN\"\n                    sh \"docker buildx create --use --platform=linux/arm64,linux/amd64 --node multi-platform-builder-${env.SERVICE} --name multi-platform-builder-${env.SERVICE}\"\n                    sh \"docker buildx build --platform=linux/arm64,linux/amd64 --push --tag ${env.NAME}:latest --tag ${env.NAME}:${env.BUILD_ID} -f DockerFile .\"\n                    sh \"docker buildx rm --force multi-platform-builder-${env.SERVICE}\"\n                }\n            }\n        }\n        stage('Deploy to EKS') {\n            steps {\n                withCredentials([\n                    string(credentialsId: 'aws-access-key-id', variable: 'AWS_ACCESS_KEY_ID'),\n                    string(credentialsId: 'aws-secret-access-key', variable: 'AWS_SECRET_ACCESS_KEY'),\n                    string(credentialsId: 'aws-region', variable: 'AWS_REGION'),\n                    string(credentialsId: 'eks-cluster-name', variable: 'CLUSTER_NAME')\n                ]) {\n                    sh \"aws eks update-kubeconfig --region ${AWS_REGION} --name ${CLUSTER_NAME}\"\n                    sh \"kubectl set image deployment/${env.SERVICE} ${env.SERVICE}=${env.NAME}:${env.BUILD_ID} -n default\"\n                    sh \"kubectl rollout status deployment/${env.SERVICE} -n default\"\n                }\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"roteiro7/#imagens-que-comprovam","title":"Imagens que comprovam:","text":"<p>Aqui temos a imagem do Jenkins rodando com tudo e como ficou o fluxo de todos os servi\u00e7os</p> Figura 1 \u2014 Tela do Jenkins com TUDO funcionando. Figura 2 \u2014 Fluxo do deploy de todos os exerc\u00edcios."},{"location":"roteiro8/","title":"An\u00e1lise de custos","text":""},{"location":"roteiro8/#analise-de-custos","title":"An\u00e1lise de custos","text":"<p>A an\u00e1lise de custos foi feita utilizando a aba Cost and usage que mostra detalhadamente onde est\u00e3o indo todos os custos e qual a previs\u00e3o de custos.</p> Figura 1 \u2014 Mostrando o Cost and usage do nosso microservi\u00e7o"},{"location":"roteiro8/#analise-detalhada","title":"An\u00e1lise detalhada:","text":"Servi\u00e7o Custo (USD) % do Total Elastic Container Service for Kubernetes $29.30 30.82% EC2 \u2013 Other $27.68 29.11% EC2 \u2013 Compute $13.37 14.06% Tax $11.54 12.14% Elastic Load Balancing $7.33 7.71% Others $5.86 6.16% Total $95.08 100% Figura 2 - mostrando para onde est\u00e3o sendo direcionados os custos"},{"location":"roteiro8/#conclusao","title":"Conclus\u00e3o:","text":"<p>Os custos atuais do ambiente totalizam US$ 95,08, com proje\u00e7\u00e3o de fechamento em US$ 217,10, refletindo um uso est\u00e1vel e coerente da infraestrutura. A maior parte do consumo concentra-se em servi\u00e7os essenciais como: - EKS/ - ECS - EC2 - Load Balancing,</p> <p>indicando que o cluster est\u00e1 corretamente dimensionado e sem desperd\u00edcios relevantes. </p> <p>Em compara\u00e7\u00e3o com meses anteriores, observa-se uma queda significativa no gasto total, refor\u00e7ando a efici\u00eancia das otimiza\u00e7\u00f5es aplicadas.</p> <p>No geral, o ambiente demonstra equil\u00edbrio entre desempenho e custo, com previsibilidade financeira e boa sa\u00fade operacional.</p>"},{"location":"roteiro9/","title":"PaaS","text":""},{"location":"roteiro9/#paas","title":"PaaS","text":"<p>Neste projeto implementamos solu\u00e7\u00f5es de PaaS (Plataforma como Servi\u00e7o) para abstrair a complexidade da infraestrutura e focar na l\u00f3gica de neg\u00f3cio e na orquestra\u00e7\u00e3o dos microsservi\u00e7os.</p>"},{"location":"roteiro9/#1-tecnologia-amazon-eks","title":"1. Tecnologia: Amazon EKS","text":"<p>A principal utiliza\u00e7\u00e3o do modelo PaaS no projeto se deu atrav\u00e9s do Amazon Elastic Kubernetes Service (EKS).</p> <p>Embora o Kubernetes, por si s\u00f3, seja um orquestrador de containers, ao utiliz\u00e1-lo na modalidade gerenciada pela AWS (EKS), ele se enquadra na defini\u00e7\u00e3o de PaaS (ou mais especificamente CaaS - Container as a Service), pois transfere para o provedor de nuvem a responsabilidade pelo gerenciamento de toda a camada de controle (Control Plane).</p>"},{"location":"roteiro9/#2-como-utilizamos-implementacao-pratica","title":"2. Como Utilizamos (Implementa\u00e7\u00e3o Pr\u00e1tica)","text":"<p>Utilizamos o PaaS (Amazon EKS) nas seguintes frentes:</p> <ul> <li>Abstra\u00e7\u00e3o do Control Plane: Ao contr\u00e1rio de uma abordagem IaaS (onde ter\u00edamos que provisionar inst\u00e2ncias EC2, instalar o Linux, configurar o <code>etcd</code> e os servidores mestres do Kubernetes manualmente), utilizamos o EKS para nos entregar um cluster pronto. A AWS ficou respons\u00e1vel pela disponibilidade, patching de seguran\u00e7a e escalabilidade dos n\u00f3s mestres.</li> <li>Orquestra\u00e7\u00e3o de Microsservi\u00e7os: Utilizamos a plataforma para fazer o deploy das nossas APIs (Product, Order, Exchange). O PaaS foi respons\u00e1vel por receber nossos manifestos (arquivos YAML de <code>Deployment</code> e <code>Service</code>) e garantir que o n\u00famero desejado de r\u00e9plicas (Pods) estivesse rodando, reiniciando automaticamente containers em caso de falha (Self-healing).</li> <li>Exposi\u00e7\u00e3o de Servi\u00e7os: Utilizamos os recursos nativos da plataforma para expor nossos microsservi\u00e7os para a rede, permitindo a comunica\u00e7\u00e3o entre eles e o acesso externo, sem a necessidade de configurar balanceadores de carga manuais no n\u00edvel do sistema operacional.</li> </ul>"},{"location":"roteiro9/#3-porque-escolhemos-este-modelo-de-paas","title":"3. Porque Escolhemos Este Modelo de PaaS","text":"<p>A escolha por este modelo de PaaS atende diretamente aos t\u00f3picos estudados no curso, especificamente:</p> <ul> <li>DevOps e Cloud Computing: A utiliza\u00e7\u00e3o do EKS permitiu que o grupo adotasse pr\u00e1ticas de NoOps na camada de infraestrutura base, focando os esfor\u00e7os de desenvolvimento na constru\u00e7\u00e3o dos pipelines de CI/CD (Jenkins) e na qualidade do c\u00f3digo das APIs.</li> <li>Gest\u00e3o de N\u00edveis de Servi\u00e7o (SLA): Ao confiar a gest\u00e3o do Control Plane \u00e0 Amazon, herdamos o SLA de disponibilidade da AWS para a API do Kubernetes, garantindo uma arquitetura mais robusta para as aplica\u00e7\u00f5es de alto desempenho propostas no projeto.</li> </ul>"},{"location":"roteiro9/#resumo-tecnico","title":"Resumo T\u00e9cnico","text":"Tecnologia Classifica\u00e7\u00e3o no Projeto Justificativa Amazon EKS PaaS / CaaS A AWS gerencia o hardware, SO e o plano de controle do Kubernetes. O grupo apenas consome a API para rodar os workloads. Docker Ferramenta / Runtime Utilizado como motor para empacotar as aplica\u00e7\u00f5es. \u00c9 a base que roda sobre o PaaS. Jenkins Ferramenta / IaaS Hospedado pelo grupo para orquestrar os pipelines. Redis Software (Container) Rodado como container dentro do cluster (neste cen\u00e1rio, atua como componente da aplica\u00e7\u00e3o, n\u00e3o como servi\u00e7o gerenciado externo)."},{"location":"thisdocumentation/","title":"This documentation","text":""},{"location":"thisdocumentation/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<p>Antes de come\u00e7ar, certifique-se de que voc\u00ea possui os seguintes pr\u00e9-requisitos instalados em seu sistema:</p> <ul> <li>Git: Para clonar o reposit\u00f3rio.</li> </ul>"},{"location":"thisdocumentation/#instalando-o-python","title":"Instalando o Python","text":"LinuxmacOSWindows <p>Instale o Python 3.8 ou superior.</p> <pre><code>sudo apt install python3 python3-venv python3-pip\npython3 --version\n</code></pre> <p>Instale o Python 3.8 ou superior.</p> <pre><code>brew install python\npython3 --version\n</code></pre> <p>Instale o Python 3.13 ou superior. Baixe o instalador do site oficial do Python (https://www.python.org/downloads/) e execute-o. Certifique-se de marcar a op\u00e7\u00e3o \"Add Python to PATH\" durante a instala\u00e7\u00e3o.</p> <pre><code>python --version\n</code></pre>"},{"location":"thisdocumentation/#usage","title":"Usage","text":"<p>Para utilizar o c\u00f3digo deste reposit\u00f3rio, siga as instru\u00e7\u00f5es a seguir:</p> <p>Clone ou fork este reposit\u00f3rio:</p> <pre><code>git clone &lt;URL_DO_REPOSITORIO&gt;\n</code></pre> <p>Crie um ambiente virtual do Python:</p> Linux/macOSWindows <pre><code>python3 -m venv env\n</code></pre> <pre><code>python -m venv env\n</code></pre> <p>Ative o ambiente virtual (voc\u00ea deve fazer isso sempre que for executar algum script deste reposit\u00f3rio):</p> Linux/macOSWindows <pre><code>source ./env/bin/activate\n</code></pre> <pre><code>.\\env\\Scripts\\activate\n</code></pre> <p>Instale as depend\u00eancias com:</p> Linux/macOSWindows <pre><code>python3 -m pip install -r requirements.txt --upgrade\n</code></pre> <pre><code>python -m pip install -r requirements.txt --upgrade\n</code></pre>"},{"location":"thisdocumentation/#deployment","title":"Deployment","text":"<p>O material utiliza o mkdocs para gerar a documenta\u00e7\u00e3o. Para visualizar a documenta\u00e7\u00e3o, execute o comando:</p> <pre><code>mkdocs serve -o\n</code></pre> <p>Para subir ao GitHub Pages, execute o comando:</p> <pre><code>mkdocs gh-deploy\n</code></pre> <p>Esse reposit\u00f3rio possui um workflow do GitHub Actions que executa o comando <code>mkdocs gh-deploy</code> sempre que houver um push na branch <code>main</code>. Assim, n\u00e3o \u00e9 necess\u00e1rio executar esse comando manualmente. Toda vez que voc\u00ea fizer um push na branch <code>main</code>, a documenta\u00e7\u00e3o ser\u00e1 atualizada automaticamente no GitHub Pages.</p> <p>Aviso 1</p> <p>Para que o github actions funcione corretamente, \u00e9 necess\u00e1rio que o reposit\u00f3rio esteja configurado para que o bot <code>github-actions[bot]</code> tenha permiss\u00e3o de escrita. Voc\u00ea pode verificar isso nas configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Actions\" e depois em \"General\". Certifique-se de que a op\u00e7\u00e3o \"Workflow permissions\" esteja definida como \"Read and write permissions\".</p> <p></p> <p>Aviso 2</p> <p>Depois de publicar, caso n\u00e3o consiga acessar a p\u00e1gina, verifique se o github pages est\u00e1 configurado corretamente. V\u00e1 at\u00e9 as configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Pages\" e verifique se a branch <code>gh-pages</code> est\u00e1 selecionada como fonte. Se n\u00e3o estiver, selecione-a e salve as altera\u00e7\u00f5es.</p> <p></p> <p>Pay Attention</p> <p>No arquivo '<code>mkdocs.yml</code>, a se\u00e7\u00e3o <code>site_url</code> deve estar configurada corretamente para o seu reposit\u00f3rio. Por exemplo, se o seu reposit\u00f3rio estiver em <code>https://github.com/usuario/repositorio</code>, a se\u00e7\u00e3o <code>site_url</code> deve ser:</p> <pre><code>site_url: https://usuario.github.io/repositorio\n</code></pre> <p>Tamb\u00e9m, certifique-se de que a se\u00e7\u00e3o <code>repo_url</code> esteja configurada corretamente para o seu reposit\u00f3rio. Por exemplo:</p> <pre><code>repo_url: https://github.com/usuario/repositorio\n</code></pre>"}]}